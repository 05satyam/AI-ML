{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ AI-Powered Multi-Step Agentic Workflow with LangGraph & OpenAI GPT4o:   Plan-and-Execute\n",
        "\n",
        "This notebook implements an **AI-powered multi-step execution system** using **LangGraph**, **LangChain**, and **OpenAI's GPT-4o**. The system follows a **structured planning, execution, and replanning process**, leveraging **ReAct (Reasoning + Acting)** methodology to dynamically break down tasks, retrieve relevant knowledge, and refine answers.\n",
        "\n",
        "---\n",
        "\n",
        "## üìå Overview\n",
        "\n",
        "### üîπ What This Notebook Does:\n",
        "- **ReAct Agent**: Implements an AI agent using **GPT-4o-mini** and integrates **Tavily API** for real-time web searches.\n",
        "- **Planning**: Generates a structured **step-by-step** execution plan using an **LLM-powered planner**.\n",
        "- **Execution**: Executes each planned step iteratively, refining responses.\n",
        "- **Replanning**: Dynamically updates the plan based on execution results.\n",
        "- **LangGraph Workflow**: Implements an **agentic execution graph** to handle decision-making.\n",
        "\n",
        "### üèóÔ∏è Core Components:\n",
        "- ‚úÖ **LangChain & OpenAI** ‚Üí AI-powered reasoning & execution.\n",
        "- ‚úÖ **Tavily API** ‚Üí Real-time web search for external knowledge retrieval.\n",
        "- ‚úÖ **LangGraph** ‚Üí Orchestrates planning, execution, and adaptive refinement.\n",
        "- ‚úÖ **Asynchronous Execution** ‚Üí Optimizes performance using `asyncio`.\n",
        "\n",
        "---\n",
        "\n",
        "## üõ†Ô∏è Installation & Setup\n",
        "\n",
        "Before running the notebook, install the required dependencies:\n",
        "\n",
        "```sh\n",
        "pip install -U langgraph langchain-community langchain-openai tavily-python python-dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrDZ5xjOHcKA"
      },
      "outputs": [],
      "source": [
        "%pip install -U langgraph langchain-community langchain-openai tavily-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xObw_JJ_HcKC",
        "outputId": "8febfb13-bdca-435f-f04a-9a4e3d92d0c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.0.1)\n"
          ]
        }
      ],
      "source": [
        "%pip install python-dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2bJiXrZHcKD"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Markdown, display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ait_Fij9HcKD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "def _set_env(key: str):\n",
        "    if not os.environ.get(key):\n",
        "        os.environ[key] = os.getenv(key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMXhXuwHHcKD"
      },
      "outputs": [],
      "source": [
        "OPENAI_API_KEY=\"sk-proj-B\"\n",
        "TAVILY_API_KEY=\"tvly-\"\n",
        "# _set_env(OPENAI_API_KEY)\n",
        "# _set_env(TAVILY_API_KEY)\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvCgedgnHcKE"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "tools = [TavilySearchResults(max_results=5)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pf27DL_VHcKE"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "llm = ChatOpenAI(model = \"gpt-4o-mini\")\n",
        "prompt = \"Be a helpful assistance and assist in the given query!!\"\n",
        "\n",
        "agent_executor = create_react_agent(llm, tools, prompt = prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "83XZEfJIHcKE"
      },
      "outputs": [],
      "source": [
        "agent_executor.invoke({\"messages\": [(\"user\", \"show me a tabulary results of different llm models by comparing them with several benchmark test.\")]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTefY2fbHcKE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3m74hoFlHcKF"
      },
      "outputs": [],
      "source": [
        "import operator\n",
        "from typing import Annotated, List, Tuple\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "class PlanExecute(TypedDict):\n",
        "    input: str\n",
        "    plan: List[str]\n",
        "    past_steps: Annotated[List[Tuple], operator.add]\n",
        "    response: str\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWLc1iaeHcKF"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class Plan(BaseModel):\n",
        "    steps: List[str] = Field(description=\"different steps to follow, and must be in sorted order\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGxSXIe9HcKF"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "planner_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\", \"\"\"For the given objective, come up with a simple step by step plan. \\\n",
        "This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \\\n",
        "The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\"\"\"\n",
        "        ),\n",
        "        (\"placeholder\", \"{messages}\")\n",
        "    ]\n",
        ")\n",
        "planner = planner_prompt | ChatOpenAI(\n",
        "    model = \"gpt-4o\",\n",
        "    temperature=0\n",
        ").with_structured_output(Plan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lg5N-rhnHcKF"
      },
      "outputs": [],
      "source": [
        "planner.invoke(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            (\"user\", \"List of all LLM models and the years they were released in increasing order\")\n",
        "        ]\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Mgg6c3JHcKF"
      },
      "outputs": [],
      "source": [
        "from typing import Union\n",
        "\n",
        "\n",
        "class Response(BaseModel):\n",
        "    \"\"\"Response to user.\"\"\"\n",
        "\n",
        "    response: str\n",
        "\n",
        "\n",
        "class Act(BaseModel):\n",
        "    \"\"\"Action to perform.\"\"\"\n",
        "\n",
        "    action: Union[Response, Plan] = Field(\n",
        "        description=\"Action to perform. If you want to respond to user, use Response. \"\n",
        "        \"If you need to further use tools to get the answer, use Plan.\"\n",
        "    )\n",
        "\n",
        "\n",
        "replanner_prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"For the given objective, come up with a simple step by step plan. \\\n",
        "This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \\\n",
        "The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\n",
        "\n",
        "Your objective was this:\n",
        "{input}\n",
        "\n",
        "Your original plan was this:\n",
        "{plan}\n",
        "\n",
        "You have currently done the follow steps:\n",
        "{past_steps}\n",
        "\n",
        "Update your plan accordingly. If no more steps are needed and you can return to the user, then respond with that. Otherwise, fill out the plan. Only add steps to the plan that still NEED to be done. Do not return previously done steps as part of the plan.\"\"\"\n",
        ")\n",
        "\n",
        "\n",
        "replanner = replanner_prompt | ChatOpenAI(\n",
        "    model=\"gpt-4o\", temperature=0\n",
        ").with_structured_output(Act)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQ6Ppqo0HcKF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1MFSsPFHcKF"
      },
      "outputs": [],
      "source": [
        "from typing import Literal\n",
        "from langgraph.graph import END\n",
        "import asyncio\n",
        "\n",
        "async def execute_step(state: PlanExecute):\n",
        "    # print(f\"states: {state}\")\n",
        "    plan = state[\"plan\"]\n",
        "    plan_str = \"\\n\".join(f\"{i+1}. {step}\" for i, step in enumerate(plan))\n",
        "    task = plan[0]\n",
        "    task_formatted = f\"\"\"For the following plan:\n",
        "{plan_str}\\n\\nYou are tasked with executing step {1}, {task}.\"\"\"\n",
        "    await asyncio.sleep(1)\n",
        "    agent_response = await agent_executor.ainvoke(\n",
        "        {\"messages\": [(\"user\", task_formatted)]}\n",
        "    )\n",
        "    # Update 'past_steps' correctly\n",
        "    past_steps = state.get(\"past_steps\", [])  # Get existing past_steps or initialize an empty list\n",
        "    past_steps.append((task, agent_response[\"messages\"][-1].content))  # Append the new step\n",
        "    return {\n",
        "        \"past_steps\": past_steps, # Return the updated past_steps\n",
        "    }\n",
        "\n",
        "async def plan_step(state: PlanExecute):\n",
        "    plan = await planner.ainvoke({\"messages\": [(\"user\", state[\"input\"])]})\n",
        "    # Include 'past_steps' in the returned dictionary, initialized as an empty list if not present\n",
        "    return {\"plan\": plan.steps, \"past_steps\": state.get(\"past_steps\", [])}\n",
        "\n",
        "\n",
        "async def replan_step(state: PlanExecute):\n",
        "    output = await replanner.ainvoke(state)\n",
        "    if isinstance(output.action, Response):\n",
        "        return {\"response\": output.action.response, \"past_steps\": state.get(\"past_steps\", [])}\n",
        "    else:\n",
        "        return {\n",
        "            \"plan\": output.action.steps,\n",
        "            \"past_steps\": state.get(\"past_steps\", []),\n",
        "        }\n",
        "\n",
        "\n",
        "def should_end(state: PlanExecute):\n",
        "    if \"response\" in state and state[\"response\"]:\n",
        "        return END\n",
        "    else:\n",
        "        return \"agent\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7Q-gPXbHcKG"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, START\n",
        "\n",
        "workflow = StateGraph(PlanExecute)\n",
        "\n",
        "\n",
        "# Add the plan node\n",
        "workflow.add_node(\"planner\", plan_step)\n",
        "\n",
        "# Add the execution step\n",
        "workflow.add_node(\"agent\", execute_step)\n",
        "\n",
        "# Add a replan node\n",
        "workflow.add_node(\"replan\", replan_step)\n",
        "\n",
        "workflow.add_edge(START, \"planner\")\n",
        "\n",
        "# From plan we go to agent\n",
        "workflow.add_edge(\"planner\", \"agent\")\n",
        "\n",
        "# From agent, we replan\n",
        "workflow.add_edge(\"agent\", \"replan\")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"replan\",\n",
        "    # Next, we pass in the function that will determine which node is called next.\n",
        "    should_end,\n",
        "    [\"agent\", END],\n",
        ")\n",
        "\n",
        "# Finally, we compile it!\n",
        "# This compiles it into a LangChain Runnable,\n",
        "# meaning you can use it as you would any other runnable\n",
        "app = workflow.compile()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JM-NywwlHcKG"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sol-nhvnHcKG"
      },
      "source": [
        "## Alignment with the Image\n",
        "\n",
        "| **Workflow Step**         | **Code**                                                                                          | **Graph Alignment**                                                                 |\n",
        "|----------------------------|--------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------|\n",
        "| **Start ‚Üí Planner**        | `workflow.add_edge(START, \"planner\")`                                                           | The workflow starts at `__start__` and moves to `planner`.                         |\n",
        "| **Planner ‚Üí Agent**        | `workflow.add_edge(\"planner\", \"agent\")`                                                        | Solid edge connects `planner` to `agent`.                                          |\n",
        "| **Agent ‚Üí Replan**         | `workflow.add_edge(\"agent\", \"replan\")`                                                         | Solid edge connects `agent` to `replan`.                                           |\n",
        "| **Replan ‚Üí Conditional**   | `workflow.add_conditional_edges(\"replan\", should_end, [\"agent\", END])`                          | Dashed edges connect `replan` to both `agent` (loop back) and `__end__` (terminate).|\n",
        "| **Agent ‚Üí End (optional)** | The `should_end` condition allows skipping `replan` and terminating the workflow directly at `END`. | Dashed edge connects `agent` to `__end__` for early termination.                   |\n",
        "\n",
        "---\n",
        "\n",
        "## Key Takeaways\n",
        "\n",
        "1. **Dynamic Flow**: The code uses conditional edges (`should_end`) to control whether the workflow loops back to `agent` or terminates.\n",
        "2. **Alignment with Graph**:\n",
        "   - Nodes (`planner`, `agent`, `replan`, `END`) and edges directly correspond to the diagram.\n",
        "   - Dashed edges represent the dynamic conditional transitions in the workflow.\n",
        "3. **Early Termination**: The `END` node can be reached either:\n",
        "   - Directly after `agent` (if execution succeeds without replanning).\n",
        "   - After `replan` (if no further steps are required).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "u1UXkt4vHcKH"
      },
      "outputs": [],
      "source": [
        "config = {\"recursion_limit\": 50}\n",
        "inputs = {\n",
        "    \"input\": \"List of all LLM models and the years they were released in increasing order after 2021 upto latest 5\",\n",
        "    \"past_steps\": []\n",
        "    }\n",
        "async for event in app.astream(inputs, config=config):\n",
        "    for k, v in event.items():\n",
        "        if k == \"response\":\n",
        "            # Print the final response as Markdown\n",
        "            print(f\"```markdown\\n{v}\\n```\")\n",
        "        elif k != \"__end__\":\n",
        "            print(v)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
